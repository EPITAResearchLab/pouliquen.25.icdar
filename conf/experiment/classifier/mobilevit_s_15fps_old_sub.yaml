# @package _global_
defaults:
  - override /valtransform: torchtransformssub

model:
  model: 
    backbone_name: mobilevit_xxs

paths:
  data_cropped_dir: ${paths.data_dir}/cropped_sub/
  frame_skip: 1


training:
  trainer:
    epochs_max: 5
  datamodule:
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: torchvision.transforms.Resize
          size: 230
        - _target_: torchvision.transforms.RandomCrop
          size: 224
        - _target_: torchvision.transforms.RandomApply
          transforms: 
            _target_: torch.nn.ModuleList
            modules:
              - _target_: torchvision.transforms.GaussianBlur
                _convert_: partial
                kernel_size: [3, 11]
                sigma: [2, 10]
          p: 0.4
        - _target_: torchvision.transforms.RandomApply
          transforms: 
            _target_: torch.nn.ModuleList
            modules:
              - _target_: torchvision.transforms.ColorJitter
                brightness: 0.3
                contrast: 0.1
                saturation: 0.05
          p: 0.4
        - _target_: torchvision.transforms.ToTensor
        - _target_: torchvision.transforms.Normalize
          mean: [0.1, 0.1, 0.1]
          std: [0.2, 0.2, 0.2]

task_name: classifierfinalfinal_old_15fps_sub_s${seed}_${model.model.backbone_name}_${paths.split_name}
